---
title: "Advanced statistics for physics analysis - Exercise 6"
author: "Matteo Bortoletto, matr. 1242935"
date: "20/05/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Exercise 1
The number of particles emitted by a radioactive source during a fixed interval of time ($\Delta t = 10$ s) follows a Poisson distribution on the parameter $\mu$. The number of particles observed during consecutive time intervals is: 4, 1, 3, 1 and 3.

a. Suppose a uniform prior distribution for the parameter $\mu$.

    - Determine and draw the posterior distribution for $\mu$, given the data. 
    - Evaluate mean, median and variance, both analytically and numerically in `R`.

```{r}
library(latex2exp)

counts <- c(4, 1, 3, 1, 3)
delta.mu <- 0.01
mu <- seq(0,10,delta.mu)

u.post <- dgamma(mu, shape = sum(counts)+1, scale = 1/5) 

plot(mu, u.post,
     lwd=1.5,
     type = "l",
     xlab = TeX("$\\mu$"),
     ylab = TeX("$P(\\mu | x_j )$"),
     col = "mediumpurple3",
     main = "Posterior obtained using uniform prior")

# Evaluate mean, median and variance, both analytically and numerically in `R`. <------------------
```

b. Suppose a Jeffrey’s prior for the parameter $\mu$. 

    - Determine and draw the posterior distribution for $\mu$, given the data. 
    - Evaluate mean, median and variance, both analytically and numerically in `R`.

```{r}
j.post <- dgamma(mu, shape = sum(counts)+0.5, scale = 1/5) 

plot(mu, j.post,
     lwd=1.5,
     type = "l",
     xlab = TeX("$\\mu$"),
     ylab = TeX("$P(\\mu | x_j )$"),
     col = "mediumpurple3",
     main = "Posterior obtained using Jeffrey's prior")

# Evaluate mean, median and variance, both analytically and numerically in `R`. <------------------
```

c. Evaluate a 95% credibility interval for the results obtained with both priors. Compare the result with that obtained using a normal approximation for the posterior distribution, with the same mean and standard deviation.

```{r}
cat("95% credibility interval with uniform prior: [x1, x2] = [", mu[which.min(abs(0.025-cumsum(u.post)*delta.mu))], 
    ",", mu[which.min(abs(0.975-cumsum(u.post)*delta.mu))], "]", "\n")
cat("95% credibility interval with uniform prior: [x1, x2] = [", mu[which.min(abs(0.025-cumsum(j.post)*delta.mu))], 
    ",", mu[which.min(abs(0.975-cumsum(j.post)*delta.mu))], "]")
```


# Exercise 2
Given the problem of the lighthouse discussed last week, study the case in which both the position along the shore ($\alpha$) and the distance out at the sea ($\beta$) are unknown.

From Bayes' theorem we have that 
$$
P(\alpha,\beta | \{x_k\}) \propto P(\{x_k\}|\alpha,\beta)P(\alpha,\beta)
$$
If we suppose that $\alpha$ and $\beta$ are independent then 

$$
P(\alpha,\beta) = P(\alpha)P(\beta)
$$
The likelihood for the angle $\theta$ is given by

$$
P(\theta | \alpha,\beta) = \frac{1}{\pi}
$$
and using the change of variable $\theta\to x$ we can write it as

$$
P(x|\alpha,\beta) = \frac{1}{\pi}\frac{\beta}{\beta^2 + (x-\alpha)^2}
$$
which is a Cauchy distribution. As before, the prior of $\alpha$ can be written as 

$$
P(\alpha)=
\begin{cases}
  \frac{1}{\alpha_{max}-\alpha_{min}} & \text{if } x\in[\alpha_{min},\alpha_{max}] \\
  0 & \text{otherwise}
\end{cases}
$$
whereas for $\beta$ we can take

$$
P(\beta) = 
\begin{cases}
  \frac{1}{h} & \text{if } x\in[0,h] \\
  0 & \text{otherwise}
\end{cases}
$$
where $h$ is the maximum distance out at sea. However, this additional prior can be absorbed in the normalization factor of the posterior, so we have

$$
P(\alpha,\beta | \{x_k\}) = \frac{1}{Z}P(\{x_k\}|\alpha,\beta) 
$$
Taking the logarithm we get

$$
L = \ln P(\alpha,\beta|\{x_k\}) = const + \ln(\beta) - \sum_j \ln\left[1+ \left(\frac{x_j-\alpha}{\beta}\right)^2\right]
$$
```{r}
p.log.like <- function(a, b, data) {
  logL <- 0.0
  for (x in data) {
    logL <- logL  - log(b*(1 + ((x-a)/b)^2)/pi)
  }
  return(logL)
}

x.k <- function(n, alpha, beta){
  theta <- runif(n, min=-pi/2, max=pi/2)
  x <- alpha + beta*tan(theta)    
  return(x)
}

f <- function(a,b) {
  p.log.like(a, b, dt)
}

beta.t = 1
alpha.t = 1

data <- x.k(200, alpha.t, beta.t)

n.sample <- 200
x.min <- -6
x.max <- +6
h <- (x.max - x.min)/n.sample
alpha <- seq(from=x.min, by=h, length.out=n.sample)
beta <- seq(from=0.001, to=2, length.out=n.sample)

oldpar <- par()
par(mfrow=c(1, 2))
options(repr.plot.width=30, repr.plot.height=30)

for(n in c(1, 2, 5, 10, 20, 50, 100, 200)) {
  n.plot <- n

  dt <- data[1:n.plot]

  log_grid_values <- outer(alpha, beta, Vectorize(f))

  post.star <- exp(log_grid_values)
  post <- post.star/(h*sum(post.star))
  
  grid_values <- matrix(post, nrow = length(alpha), ncol = length(beta))
  
  index.max <- c(which(grid_values == max(grid_values), arr.ind = TRUE))
  alpha.max <- alpha[index.max[1]]
  beta.max <- beta[index.max[2]]
  #cat("-- Number of collected data:", n, "\n")
  #cat("Alpha max =", alpha.max, "\t Beta max =", beta.max, "\n")

  persp(alpha, beta, grid_values, 
        xlab = "alpha", 
        ylab = "beta", 
        zlab = "Posterior", 
        main = paste("Set dimension = ", n), 
        sub = paste("AlphaMax =", alpha.max, "\n", "BetaMax =", round(beta.max, digits = 2)),
        cex = 0.7, 
        lwd = 0.1, 
        theta = 150, 
        phi = 30, 
        shade = 0.05)
}
```


# Exercise 3
Given the Signal over Background example discussed last week, analyze and discuss the following cases:

a. Vary the sampling resolution used to generate the data, keeping the same sampling range:

`xdat <- seq(from=-7*w, to=7*w, by=0.5*w)`

Use $w = \{0.1,0.25,1,2,3\}$. Check the effect on the results.

```{r, fig.height=15, fig.width=9}
# Generative model
signal <- function(x, a, b, x0, w, t) {
  return(t*(a*exp(-(x-x0)^2/(2*w^2))+b))
}

# Model parameters
x0 <- 0
A.true <- 2
B.true <- 1
Delta.t <- 5
sampling.range <- 1

# Log posterior
log.post <- function(d, x, a, b, x0, w, t) {
  if(a<0 || b <0) {
    return(-Inf) # the effect of the prior
  }  
  sum(dpois(d, lambda=signal(x, a, b, x0, w, t), log=TRUE))
}

# Sampling grid for computing posterior
alim <- c(0.0, 4.0)
blim <- c(0.5, 1.5)
Nsamp <- 100
uniGrid <- seq(from=1/(2*Nsamp), to=1-1/(2*Nsamp), by=1/Nsamp) 
delta_a <- diff(alim)/Nsamp 
delta_b <- diff(blim)/Nsamp
a <- alim[1] + diff(alim)*uniGrid 
b <- blim[1] + diff(blim)*uniGrid

# Compute log unnormalized posterior, z = ln Pˆ*(a,b|D), on a regular grid
z <- matrix(data=NA, nrow=length(a), ncol=length(b)) 

w.values <- c(0.1, 0.25, 1, 2, 3)

p.area <- matrix(c(1,2,
                   3,4,
                   5,6,
                   7,8,
                   9,10), nrow=5, ncol=2, byrow=TRUE)

layout(p.area)

for(w in w.values) {
  set.seed(205)

  xdat <- seq(from = -7*sampling.range, to = 7*sampling.range, by = 0.5*w)
  s.true <- signal(xdat, A.true, B.true, x0, w, Delta.t)
  ddat <- rpois(length(s.true), s.true)

  xplot <- seq(from = min(xdat), to = max(xdat), by = 0.05*w)
  splot <- signal(xplot, A.true, B.true, x0, w, Delta.t)

  plot(xplot, splot,
       xlab = "x",
       ylab = "Signal + Background counts",
       main = paste("Data generated for w =", w),
       type = "l",
       lwd = 1.5,
       col = "mediumpurple3",
       xlim = range(xplot),
       ylim = range(c(splot, ddat)))

  xdat.off <- xdat - 0.25

  lines(xdat.off, ddat, 
       type = "s", 
       col = "orange2", 
       lwd = 1.5)
  
  for(j in 1:length(a)) {
    for(k in 1:length(b)) {
      z[j,k] <- log.post(ddat, xdat, a[j], b[k], x0, w, Delta.t)
    } 
  }

  z <- z - max(z) # set maximum to zero

  # Plot unnormalized 2D posterior 
  contour(a, b, exp(z), 
          nlevels = 5, 
          labcex = 0.5,
          lwd = 2, 
          xlab="amplitude, A", 
          ylab="background, B")

  abline(v=2,h=1,col="grey")
}
```

b. Change the ratio $A/B$ used to simulate the data (keeping both positive in accordance with the prior). Check the effect on the results.

```{r, fig.height=15, fig.width=9}
# Generative model
signal <- function(x, a, b, x0, w, t) {
  return(t*(a*exp(-(x-x0)^2/(2*w^2))+b))
}

# Log posterior
log.post <- function(d, x, a, b, x0, w, t) {
  if(a<0 || b <0) {
    return(-Inf) # the effect of the prior
  }  
  sum(dpois(d, lambda=signal(x, a, b, x0, w, t), log=TRUE))
}

# Sampling grid for computing posterior
alim <- c(0.0, 4.0)
blim <- c(0.5, 2.5)
Nsamp <- 100
uniGrid <- seq(from=1/(2*Nsamp), to=1-1/(2*Nsamp), by=1/Nsamp) 
delta_a <- diff(alim)/Nsamp 
delta_b <- diff(blim)/Nsamp
a <- alim[1] + diff(alim)*uniGrid 
b <- blim[1] + diff(blim)*uniGrid

# Compute log unnormalized posterior, z = ln Pˆ*(a,b|D), on a regular grid
z <- matrix(data=NA, nrow=length(a), ncol=length(b)) 

p.area <- matrix(c(1,2,
                   3,4,
                   5,6,
                   7,8), nrow=4, ncol=2, byrow=TRUE)

layout(p.area)

AoverB <- c(2.5, 2, 1.5, 1)

for(r in AoverB) {
  # Model parameters
  x0 <- 0
  w <- 1
  A.true <- 2
  B.true <- 2/r
  Delta.t <- 5
  
  set.seed(205)
  xdat <- seq(from = -7*w, to = 7*w, by = 0.5*w)
  s.true <- signal(xdat, A.true, B.true, x0, w, Delta.t)
  ddat <- rpois(length(s.true), s.true)

  xplot <- seq(from = min(xdat), to = max(xdat), by = 0.05*w)
  splot <- signal(xplot, A.true, B.true, x0, w, Delta.t)

  plot(xplot, splot,
       xlab = "x",
       ylab = "Signal + Background counts",
       main = paste("Data generated for A/B =", r),
       type = "l",
       lwd = 1.5,
       col = "mediumpurple3",
       xlim = range(xplot),
       ylim = range(c(splot, ddat)))

  xdat.off <- xdat - 0.25

  lines(xdat.off, ddat, 
       type = "s", 
       col = "orange2", 
       lwd = 1.5)

  for(j in 1:length(a)) {
    for(k in 1:length(b)) {
      z[j,k] <- log.post(ddat, xdat, a[j], b[k], x0, w, Delta.t)
    } 
  }

  z <- z - max(z) # set maximum to zero

  # Plot unnormalized 2D posterior 
  contour(a, b, exp(z), 
          nlevels = 5, 
          labcex = 0.5,
          lwd = 2, 
          xlab="amplitude, A", 
          ylab="background, B")

  abline(v=2,h=1,col="grey")
}
```
